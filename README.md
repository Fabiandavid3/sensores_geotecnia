# ğŸ§  Chatbot RAG para Monitoreo GeotÃ©cnico

Este proyecto implementa un sistema de RecuperaciÃ³n Aumentada por GeneraciÃ³n (RAG) que responde preguntas sobre documentos tÃ©cnicos relacionados con sensores, taludes y movimientos en masa en Colombia. Utiliza LangChain, OpenAI, FAISS, Streamlit y MLflow para ingesta, vectorizaciÃ³n, generaciÃ³n de respuestas y evaluaciÃ³n automÃ¡tica.

---

## ğŸ“ DesafÃ­o educativo - SoluciÃ³n desarrollada

### ğŸ§© Parte 1: PersonalizaciÃ³n del dominio

- **Dominio elegido**: Monitoreo geotÃ©cnico en proyectos de infraestructura.
- **Fuentes**: Documentos PDF de campo sobre sensores, monitoreo de taludes y manuales de calidad.
- **UbicaciÃ³n de los documentos**: `data/pdfs/`
- **Prompts personalizados**: Incluidos en `app/prompts/` (versiones `v1_asistente_geotecnia`, `v2_resumido`, `v3_directo_flexible`).
- **Conjunto de evaluaciÃ³n**: `tests/eval_dataset.json` con 13 preguntas especÃ­ficas y sus respuestas de referencia.

ğŸ“¸ *Sugerencia de imagen:* Captura de `data/pdfs/` y estructura de prompts (`app/prompts/`)

---

### âœ… Parte 2: EvaluaciÃ³n automÃ¡tica con LangChain

- Script `app/run_eval_new.py` ejecuta la evaluaciÃ³n automÃ¡tica.
- EvalÃºa con `LabeledCriteriaEvalChain` y `QAEvalChain` de LangChain.
- MÃ©tricas generadas:
  - `correctness_score`
  - `relevance_score`
  - `coherence_score`
  - `toxicity_score`
  - `harmfulness_score`
  - `clarity_score` (Bonus)
  - `qa_score` (binaria)

ğŸ“¸ *Sugerencia de imagen:* Vista en MLflow mostrando mÃ©tricas de una run (`eval_q11`)

---

### ğŸ‘¨â€ğŸ”¬ Parte 3: Sistema de evaluaciÃ³n extendido

- Se integrÃ³ evaluaciÃ³n multicriterio con razonamientos generados por el LLM.
- Cada criterio registra:
  - Score (como mÃ©trica)
  - Texto razonado (como parÃ¡metro y artifact `.txt`)

ğŸ“¸ *Sugerencia de imagen:* Artifact cargado en MLflow con razonamiento (`harmfulness_reasoning_11.txt`)

---

### ğŸ“Š Parte 4: Mejora del dashboard

- Streamlit Dashboard (`dashboard.py`) permite:
  - Visualizar mÃ©tricas por ejecuciÃ³n
  - Comparar configuraciones de chunk y prompt
  - Mostrar razonamientos generados
  - Comparar mÃ©tricas por pregunta en grÃ¡fico radar

ğŸ“¸ *Sugerencia de imagen:* Radar de una pregunta + tabla general de mÃ©tricas

---

### ğŸ¤ Parte 5: ReflexiÃ³n y comparaciones

- Se compararon versiones `v1_asistente_geotecnia`, `v2_resumido`, `v3_directo_flexible`.
- La versiÃ³n `v3` obtuvo las puntuaciones mÃ¡s altas en claridad, coherencia y relevancia.
- Se observaron fallos frecuentes en `correctness` por ambigÃ¼edad en la extracciÃ³n del contexto.
- Toxicidad y daÃ±o siempre puntuaron bajo (lo esperado).

ğŸ“¸ *Sugerencia de imagen:* Comparativa de configuraciones por mÃ©trica en grÃ¡fico de barras

---

### ğŸš€ Bonus: Nuevo criterio â€” "claridad"

- Se implementÃ³ un nuevo criterio: `clarity`
- DefiniciÃ³n: *Â¿Es clara y fÃ¡cil de entender la respuesta para un lector no experto?*
- Integrado en el pipeline de evaluaciÃ³n y visualizaciÃ³n.

ğŸ“¸ *Sugerencia de imagen:* `clarity_score` en tabla de dashboard o ejemplo de razonamiento generado

---

## ğŸ§ª CÃ³mo ejecutar el proyecto

### 1. Instala dependencias

```bash
pip install -r requirements.txt
