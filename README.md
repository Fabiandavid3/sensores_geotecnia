# ğŸ§  Chatbot RAG para Monitoreo GeotÃ©cnico

Este proyecto implementa un sistema de RecuperaciÃ³n Aumentada por GeneraciÃ³n (RAG) para responder preguntas tÃ©cnicas sobre monitoreo geotÃ©cnico en Colombia, usando LangChain, OpenAI, FAISS, Streamlit y MLflow. EstÃ¡ desarrollado como soluciÃ³n al desafÃ­o educativo propuesto en PyCon 2025.

---

## ğŸ”— Basado en

> Todo el proyecto fue adaptado y extendido a partir del repositorio original:  
> [GenAIOps_Pycon2025](https://github.com/darkanita/GenAIOps_Pycon2025/tree/main)  
>  
> ğŸ“– El paso a paso detallado para su ejecuciÃ³n y estructura base se encuentra documentado allÃ­.

---

## ğŸ“ DesafÃ­o educativo - SoluciÃ³n desarrollada

### ğŸ§© Parte 1: PersonalizaciÃ³n del dominio

- **Dominio elegido**: Monitoreo geotÃ©cnico en obras de infraestructura.
- **PDFs cargados**: Documentos tÃ©cnicos reales de sensores, informes de taludes y manuales de calidad.
- **Prompts personalizados**:
  - `v1_asistente_geotecnia`
  - `v2_resumido_directo`
  - `v3_directo_flexible`
- **Dataset de evaluaciÃ³n**: `tests/eval_dataset.json`

ğŸ“¸ *RecomendaciÃ³n de imagen:* Captura de `data/pdfs/` y los prompts en `app/prompts/`

![data/pdfs/](img\data-pdfs.png)

![app/prompts/](img\promptv3.png)

---

### âœ… Parte 2: EvaluaciÃ³n automÃ¡tica con LangChain

- Implementado en `app/run_eval_new.py`
- MÃ©tricas:
  - `correctness_score`
  - `relevance_score`
  - `coherence_score`
  - `toxicity_score`
  - `harmfulness_score`
  - `qa_score` (binaria)
  - `clarity_score` (Bonus)

ğŸ“¸ *RecomendaciÃ³n:* Imagen de los resultados en MLflow con todas las mÃ©tricas

---

### ğŸ‘¨â€ğŸ”¬ Parte 3: EvaluaciÃ³n extendida

- Uso de `LabeledCriteriaEvalChain` con razonamientos.
- Cada criterio registra:
  - `score` como mÃ©trica
  - Razonamiento como parÃ¡metro truncado
  - Archivo `.txt` como artifact

ğŸ“¸ *RecomendaciÃ³n:* Vista de artifact subido (`coherence_reasoning_11.txt`)

---

### ğŸ“Š Parte 4: Dashboard mejorado

- Streamlit (`dashboard.py`) visualiza:
  - Runs por configuraciÃ³n
  - Radar por pregunta
  - Comparaciones por mÃ©trica
  - Razonamientos por pregunta/criterio

ğŸ“¸ *RecomendaciÃ³n:* Captura del radar + barra comparativa

---

### ğŸ¤ Parte 5: ReflexiÃ³n y comparaciÃ³n

- La mejor configuraciÃ³n fue `v3_directo_flexible` con chunks de 512.
- La versiÃ³n `v1` mostrÃ³ fallos en claridad y relevancia.
- Los razonamientos generados permitieron analizar las causas de los errores.

ğŸ“¸ *RecomendaciÃ³n:* Imagen del dashboard con tabla y razonamientos desplegados

---

### ğŸš€ BONUS: Nuevo criterio "claridad"

- Se integrÃ³ el criterio `clarity_score` como evaluaciÃ³n adicional.
- EvaluaciÃ³n: *Â¿La respuesta es clara, fÃ¡cil de entender y libre de ambigÃ¼edad?*

ğŸ“¸ *RecomendaciÃ³n:* Imagen del `clarity_score` y razonamiento generado.

---

## ğŸ§ª CÃ³mo ejecutar el proyecto

### 1. Instala dependencias

```bash
pip install -r requirements.txt